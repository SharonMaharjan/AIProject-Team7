{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install selenium\n",
    "%pip install requests\n",
    "%pip install Pillow\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google images scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "180\n",
      "200\n",
      "180\n",
      "200\n",
      "180\n",
      "200\n",
      "180\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Define the categories\n",
    "categories = [\"Apis mellifera\"]\n",
    "driver.get(f\"https://www.google.com/imghp\")\n",
    "deny_button = driver.find_element(By.CSS_SELECTOR, \".QS5gu.sy4vM\")\n",
    "deny_button.click()\n",
    "\n",
    "# Scrape the first 200 images for each category\n",
    "for category in categories:\n",
    "    driver.get(f\"https://www.google.com/imghp\") # Google images\n",
    "    # Find the search bar and enter the search term\n",
    "    search_bar = driver.find_element(By.NAME, \"q\")\n",
    "    search_bar.send_keys(category)\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(3)\n",
    "    # Scroll down to load more images\n",
    "    image_container = driver.find_element(By.CLASS_NAME, \"mJxzWe\")\n",
    "\n",
    "    image_count = 0\n",
    "    image_urls = []\n",
    "    load_more_button = None\n",
    "    while image_count < 20:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        load_more_button = None\n",
    "        try:\n",
    "            load_more_button = image_container.find_elements(By.CLASS_NAME, \"LZ4I\")[0]\n",
    "            if load_more_button != None:\n",
    "                load_more_button.click()\n",
    "                load_more_button = None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        time.sleep(3.5)\n",
    "        images = image_container.find_elements(By.CLASS_NAME, \"Q4LuWd\")\n",
    "        \n",
    "        for image in images:\n",
    "            # Wait for the image to load\n",
    "            while True:\n",
    "                if image.get_attribute(\"src\") != None:\n",
    "                    break\n",
    "                else:\n",
    "                    time.sleep(1)\n",
    "            image_url = image.get_attribute(\"src\")\n",
    "            if \"base64\" not in image_url and image != None:\n",
    "                image_urls.append(image_url)\n",
    "            if len(image_urls) == 20:\n",
    "                break  \n",
    "        image_count = len(image_urls)\n",
    "        print(image_count)\n",
    "\n",
    "    # Create a folder with category name and download the first 100 images inside it\n",
    "    folder_name = f\"./categories/{category}\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    for i in range(20):\n",
    "            image_url = image_urls[i]\n",
    "            file_name = f\"{category}_{i+1}.jpg\"\n",
    "            file_path = os.path.join(folder_name, file_name)\n",
    "            file = open(file_path, \"wb\")\n",
    "            file.write(requests.get(image_url).content)\n",
    "            file.close()\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\appel\\\\OneDrive\\\\Bureaublad\\\\school\\\\3AI\\\\Artificial_Intelligence\\\\code\\\\AI\\\\Lessons\\\\11. DL - Introduction to Deep Learning\\\\datasets.zip'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shutil.make_archive('datasets', 'zip', './datasets/')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOL00iWsbKR3tJD1mDkcc/s",
   "gpuType": "T4",
   "mount_file_id": "1nZN_Lhf-L8jAKhlBzVyaSRo0DzyvHhDT",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
